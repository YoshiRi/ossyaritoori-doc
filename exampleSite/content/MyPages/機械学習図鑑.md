---
title: 機械学習図鑑
description: |-
  加藤公一監修
  翔泳社
categories:
  - 教科書memo
date: 2019-08-21T07:28:34.831Z
dropCap: true
displayInMenu: false
displayInList: false
draft: false
---

# 2章：正則化

- 正則化：フィッティングするモデルの複雑さにペナルティ。過学習を防ぐ。
- Ridge回帰：重み（係数）の二乗和を足す。
- Lasso回帰：絶対値の和を足す。スパースなモデルを組みやすい？
- Ridgeが円形のペナルティ，Lassoはダイア型


# 3-5章：SVMなど

- SVM：マージン最大化
- ハードマージン/ソフトマージンで外れ値への対応などが変わる
- カーネル法：線形で分けられないデータをより高次元なデータの写像とみなして線形分離を適用する手法
- シグモイド，多項，RBFなど様々なものがある

# 10：kNN
古くから知られるk近傍法は単純な計算で比較的複雑な境界を計算可能

- 学習時：データをひたすら覚える
- 分類時：入力データの近傍k個のデータのラベルから多数決する

- kが小さいと過学習。kが大きくなるに連れ分類が弱くなる

# 11：LSA
- 1988 Scottらが提案した似た意味の言葉を検索するための次元削減技術？
- 文書中に出現した単語数を行列につめる。横軸文章のNo,縦軸単語の種類
- SVDで主成分を抽出。X=UDV^Tのうち，UDを用いることで要素の次元を圧縮
- 圧縮された分類において値が大きいものはその分類に属する可能性が高い
- NMFやLDA？
- 行列がバカでかくなるので計算量が多い。モデルの更新がむずい。
